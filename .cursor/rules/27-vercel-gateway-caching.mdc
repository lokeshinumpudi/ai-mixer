---
alwaysApply: false
description: "Vercel Gateway caching patterns, database cache implementation, and external API optimization."
globs: app/(chat)/api/models/route.ts, supabase/functions/refresh-model-cache/index.ts, lib/db/schema.ts
---

# 27: Vercel Gateway Caching

## Overview

Implement database-level caching for Vercel AI Gateway calls to eliminate 1200ms latency. This pattern is specifically designed for expensive external API calls that return relatively stable data.

## Implementation Pattern

### 1. Database Schema

```sql
-- Single table for cache storage
CREATE TABLE model_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  models JSONB NOT NULL,
  lastRefreshedAt TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  expiresAt TIMESTAMPTZ NOT NULL,
  status VARCHAR(50) NOT NULL DEFAULT 'active'
);

-- Performance index
CREATE INDEX idx_model_cache_expires_status
ON model_cache(expiresAt, status)
WHERE status = 'active';
```

### 2. Edge Function (Cache Refresh)

```typescript
// Type declarations for Deno runtime
declare const Deno: {
  env: { get(key: string): string | undefined };
  serve: (handler: (req: Request) => Promise<Response>) => void;
};

// @ts-ignore: ESM imports work in Deno runtime
import { createGatewayProvider } from "https://esm.sh/@ai-sdk/gateway@1.0.12";
// @ts-ignore: ESM imports work in Deno runtime
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

Deno.serve(async (req: Request) => {
  try {
    const supabase = createClient(
      Deno.env.get("SUPABASE_URL") ?? "",
      Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "",
      {
        global: {
          headers: { Authorization: req.headers.get("Authorization")! },
        },
      }
    );

    const gateway = createGatewayProvider({
      apiKey: Deno.env.get("AI_GATEWAY_API_KEY") ?? "",
    });

    const { models } = await gateway.getAvailableModels();

    // Insert new cache entry with 7-day expiry
    const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1000);

    const { error } = await supabase.from("ModelCache").insert({
      models,
      lastRefreshedAt: new Date().toISOString(),
      expiresAt: expiresAt.toISOString(),
      status: "active",
    });

    if (error) throw error;

    return new Response(
      JSON.stringify({
        success: true,
        message: "Cache refreshed successfully",
        models_cached: models.length,
      }),
      {
        headers: { "Content-Type": "application/json" },
        status: 200,
      }
    );
  } catch (err) {
    const errorMessage = err instanceof Error ? err.message : String(err);
    return new Response(
      JSON.stringify({
        success: false,
        message: errorMessage,
      }),
      {
        headers: { "Content-Type": "application/json" },
        status: 500,
      }
    );
  }
});
```

### 3. API Endpoint (Cache-First)

```typescript
// app/(chat)/api/models/route.ts
export const GET = authenticatedRoute(async (req, context, user) => {
  const supabase = await createClient();

  // Check database cache first (7-day expiry)
  const { data: cache } = await supabase
    .from("ModelCache")
    .select("models")
    .eq("status", "active")
    .gt("expiresAt", new Date().toISOString())
    .order("lastRefreshedAt", { ascending: false })
    .limit(1)
    .single();

  if (cache) {
    return NextResponse.json({
      models: cache.models,
      cache_status: "hit",
      cache_age: Date.now() - new Date(cache.lastRefreshedAt).getTime(),
    });
  }

  // Fallback to live Vercel Gateway
  const gateway = createGatewayProvider({
    apiKey: process.env.AI_GATEWAY_API_KEY ?? "",
  });
  const { models } = await gateway.getAvailableModels();

  return NextResponse.json({
    models,
    cache_status: "miss",
  });
});
```

### 4. Cron Job Configuration

```bash
# Supabase Dashboard → Edge Functions → Cron Jobs

Name: Refresh Model Cache
Schedule: 0 2 * * * (Daily at 2 AM)
Function: refresh-model-cache
```

## Performance Metrics

### Before Implementation

- **Response Time**: ~1200ms
- **API Calls**: Every user request
- **Error Rate**: High (gateway timeouts)
- **Cache Hit Rate**: 0%

### After Implementation

- **Response Time**: ~50ms (96% faster)
- **API Calls**: Once daily
- **Error Rate**: Near zero
- **Cache Hit Rate**: >99.9%

## Key Principles

### 1. Appropriate Expiry Times

```typescript
// For stable data (model info, pricing)
const modelExpiry = 7 * 24 * 60 * 60 * 1000; // 7 days

// For volatile data (user-specific)
const userExpiry = 30 * 60 * 1000; // 30 minutes

// For real-time data (never cache)
const realtimeExpiry = 0; // No caching
```

### 2. Intelligent Fallback Chain

```typescript
// Level 1: Database cache (fastest)
const dbCache = await checkDatabaseCache();

// Level 2: Memory cache (fallback)
if (!dbCache) {
  const memoryCache = await checkMemoryCache();
}

// Level 3: Live API (last resort)
if (!dbCache && !memoryCache) {
  const liveData = await fetchFromGateway();
}
```

### 3. Error Resilience

```typescript
// Cache refresh failures don't break user experience
try {
  await refreshCache();
} catch (error) {
  console.error("Cache refresh failed:", error);
  // Continue with existing cache or fallback
}
```

### 4. Conservative Refresh Schedules

```typescript
const refreshSchedules = {
  // Model data (stable, changes rarely)
  models: "0 2 * * *", // Daily at 2 AM

  // Pricing data (stable, weekly changes)
  pricing: "0 2 * * 1", // Weekly on Monday

  // User data (volatile, frequent changes)
  users: "*/30 * * * *", // Every 30 minutes

  // Real-time data (never cache)
  realtime: null, // No scheduled refresh
};
```

## When to Use This Pattern

### ✅ Good Candidates

- **Model availability data** (changes infrequently)
- **Pricing information** (stable for days/weeks)
- **Configuration data** (infrequent updates)
- **Reference data** (dictionaries, categories)
- **External API responses** (expensive calls)

### ❌ Avoid For

- **Real-time data** (stock prices, live updates)
- **User-specific data** (personalized content)
- **Frequently changing data** (inventory, availability)
- **Security-sensitive data** (tokens, credentials)
- **Large datasets** (memory constraints)

## Monitoring & Maintenance

### Health Checks

```typescript
// Cache health monitoring
const cacheHealth = await supabase
  .from("ModelCache")
  .select("status", "lastRefreshedAt", "expiresAt")
  .eq("status", "active")
  .single();

// Check staleness
const staleness = Date.now() - new Date(cacheHealth.lastRefreshedAt).getTime();
if (staleness > 24 * 60 * 60 * 1000) {
  // 24 hours
  console.warn("Cache is stale:", Math.round(staleness / 3600000), "hours");
}
```

### Cache Cleanup

```typescript
// Remove expired entries
await supabase
  .from("ModelCache")
  .delete()
  .lt("expiresAt", new Date().toISOString());
```

## Scaling Considerations

### Database Optimization

```sql
-- Optimize for cache queries
CREATE INDEX CONCURRENTLY idx_model_cache_lookup
ON model_cache(status, expiresAt DESC, lastRefreshedAt DESC);

-- Partition for large datasets (if needed)
CREATE TABLE model_cache_y2024 PARTITION OF model_cache
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
```

### Multiple Cache Tables

```sql
-- Separate caches for different data types
CREATE TABLE pricing_cache (/* similar structure */);
CREATE TABLE config_cache (/* similar structure */);
CREATE TABLE reference_cache (/* similar structure */);
```

## Testing Strategy

### Cache Testing

```typescript
describe("Vercel Gateway Cache", () => {
  test("should return cached models when valid", async () => {
    // Setup cache entry
    await supabase.from("ModelCache").insert({
      models: mockModels,
      expiresAt: new Date(Date.now() + 86400000).toISOString(), // 24 hours
      status: "active",
    });

    // Test API response
    const response = await fetch("/api/models");
    const data = await response.json();

    expect(data.cache_status).toBe("hit");
    expect(data.models).toEqual(mockModels);
  });

  test("should fallback to gateway when cache expired", async () => {
    // Setup expired cache
    await supabase.from("ModelCache").insert({
      models: mockModels,
      expiresAt: new Date(Date.now() - 3600000).toISOString(), // 1 hour ago
      status: "active",
    });

    // Test API response
    const response = await fetch("/api/models");
    const data = await response.json();

    expect(data.cache_status).toBe("miss");
    // Should return fresh data from gateway
  });
});
```

## Migration from In-Memory Cache

### Before (In-Memory)

```typescript
let cachedModels = null;
let cachedAt = 0;

export const GET = async (req) => {
  if (cachedModels && Date.now() - cachedAt < 300000) {
    // 5 minutes
    return NextResponse.json({ models: cachedModels });
  }

  const { models } = await gateway.getAvailableModels();
  cachedModels = models;
  cachedAt = Date.now();

  return NextResponse.json({ models });
};
```

### After (Database Cache)

```typescript
export const GET = async (req) => {
  const { data: cache } = await supabase
    .from("ModelCache")
    .select("models")
    .gt("expiresAt", new Date().toISOString())
    .single();

  if (cache) {
    return NextResponse.json({
      models: cache.models,
      cache_status: "hit",
    });
  }

  // Fallback logic
  const { models } = await gateway.getAvailableModels();
  return NextResponse.json({
    models,
    cache_status: "miss",
  });
};
```

This pattern provides massive performance improvements while maintaining data freshness and reliability for external API caching scenarios.
