---
description: AI SDK integration patterns, multi-provider model system, tool definitions, and streaming implementations
---

# AI SDK Integration & Multi-Provider Model System

## AI SDK Architecture

### Core Configuration

- **Multi-provider system** with dynamic model mapping in [lib/ai/models.ts](mdc:lib/ai/models.ts) and [lib/ai/providers.ts](mdc:lib/ai/providers.ts)
- **Flexible model definitions** with provider, reasoning, and artifact capabilities
- **Dynamic entitlements** based on user type and model capabilities
- **Streaming responses** with real-time updates and data transmission
- **Tool calling** with structured schemas for enhanced functionality

### Model System Architecture

```typescript
// Reference: lib/ai/models.ts - New flexible model interface
export interface ChatModel {
  id: string; // Format: "provider:model-name"
  name: string; // Display name
  description: string; // User-friendly description
  provider: string; // Provider identifier (xai, openai, etc.)
  supportsReasoning: boolean; // Shows step-by-step reasoning
  supportsArtifacts: boolean; // Can use artifact tools
}

export const chatModels: Array<ChatModel> = [
  {
    id: "xai:grok-3-mini",
    name: "Grok 3 Mini",
    description: "Fast and efficient model for general chat",
    provider: "xai",
    supportsReasoning: false,
    supportsArtifacts: true,
  },
  // Additional models...
];
```

### Dynamic Provider Configuration

```typescript
// Reference: lib/ai/providers.ts - Dynamic model mapping
const createLanguageModels = () => {
  const models: Record<string, any> = {};

  // Add all chat models dynamically
  for (const model of chatModels) {
    const baseModelId = model.id.split(":")[1]; // Extract model ID after provider prefix

    if (model.provider === "xai") {
      if (model.supportsReasoning) {
        models[model.id] = wrapLanguageModel({
          model: xai(baseModelId),
          middleware: extractReasoningMiddleware({ tagName: "think" }),
        });
      } else {
        models[model.id] = xai(baseModelId);
      }
    }
    // Future: Add other providers like OpenAI, Anthropic, etc.
  }

  return models;
};
```

### Chat Integration Pattern

```typescript
// Reference: components/chat.tsx
import { useChat } from "@ai-sdk/react";
import { DefaultChatTransport } from "ai";

const { messages, sendMessage, status, stop, regenerate, resumeStream } =
  useChat<ChatMessage>({
    id,
    messages: initialMessages,
    experimental_throttle: 100,
    generateId: generateUUID,
    transport: new DefaultChatTransport({
      api: "/api/chat",
      fetch: fetchWithErrorHandlers,
      prepareSendMessagesRequest({ messages, id, body }) {
        return {
          body: {
            id,
            message: messages.at(-1),
            selectedChatModel: initialChatModel,
            selectedVisibilityType: visibilityType,
            ...body,
          },
        };
      },
    }),
  });
```

## Enhanced Entitlements System

### Dynamic Model Filtering

```typescript
// Reference: lib/ai/entitlements.ts - New dynamic approach
interface Entitlements {
  maxMessagesPerDay: number;
  getAvailableModels: () => Array<ChatModel>;
}

export const entitlementsByUserType: Record<UserType, Entitlements> = {
  guest: {
    maxMessagesPerDay: 20,
    getAvailableModels: () => {
      // Guest users get access to basic models only
      return chatModels.filter(
        (model) => model.id.includes("grok-3-mini") // Only mini models for guests
      );
    },
  },
  regular: {
    maxMessagesPerDay: 100,
    getAvailableModels: () => {
      // Regular users get access to all models
      return chatModels;
    },
  },
};

// Helper functions for backward compatibility
export const getAvailableModelsForUser = (
  userType: UserType
): Array<ChatModel> => {
  return entitlementsByUserType[userType].getAvailableModels();
};
```

## Tool Development Patterns

### Tool Definition Structure

All tools follow this pattern from [lib/ai/tools/](mdc:lib/ai/tools/):

```typescript
// Reference: lib/ai/tools/create-document.ts
import { tool } from "ai";
import { z } from "zod";
import type { Session } from "next-auth";

interface ToolProps {
  session: Session;
  dataStream: UIMessageStreamWriter<ChatMessage>;
}

export const toolName = ({ session, dataStream }: ToolProps) =>
  tool({
    description: "Clear description of what the tool does",
    inputSchema: z.object({
      param1: z.string(),
      param2: z.enum(["option1", "option2"]),
    }),
    execute: async ({ param1, param2 }) => {
      // Tool implementation

      // Stream data updates
      dataStream.write({
        type: "data-kind",
        data: param2,
        transient: true,
      });

      return {
        result: "Tool execution result",
      };
    },
  });
```

### Available Tools

- **[create-document.ts](mdc:lib/ai/tools/create-document.ts)** - Creates artifacts (text, code, image, sheet)
- **[update-document.ts](mdc:lib/ai/tools/update-document.ts)** - Updates existing documents
- **[get-weather.ts](mdc:lib/ai/tools/get-weather.ts)** - Weather information retrieval
- **[request-suggestions.ts](mdc:lib/ai/tools/request-suggestions.ts)** - Document suggestions

## Enhanced API Route Patterns

### Model-Aware Chat API

```typescript
// Reference: app/(chat)/api/chat/route.ts - Enhanced with model validation
export async function POST(request: Request) {
  const session = await auth();
  const { selectedChatModel } = await request.json();

  // Validate user has access to selected model
  const availableModels = getAvailableModelsForUser(session.user.type);
  const selectedModel = availableModels.find(
    (model) => model.id === selectedChatModel
  );

  if (!selectedModel) {
    return new ChatSDKError("forbidden:chat").toResponse();
  }

  // Configure tools based on model capabilities
  const result = await streamText({
    model: myProvider.languageModel(selectedChatModel),
    system: systemPrompt({ selectedModel, requestHints }),
    experimental_activeTools: selectedModel.supportsArtifacts
      ? ["getWeather", "createDocument", "updateDocument", "requestSuggestions"]
      : ["getWeather"],
    tools: {
      getWeather,
      createDocument: createDocument({ session, dataStream }),
      updateDocument: updateDocument({ session, dataStream }),
      requestSuggestions: requestSuggestions({ session, dataStream }),
    },
  });

  return result.toUIMessageStream({
    sendReasoning: selectedModel.supportsReasoning,
  });
}
```

### Dynamic Schema Validation

```typescript
// Reference: app/(chat)/api/chat/schema.ts - Dynamic model validation
import { chatModels } from "@/lib/ai/models";

// Create dynamic enum from available models
const availableModelIds = chatModels.map((model) => model.id) as [
  string,
  ...string[]
];

export const postRequestBodySchema = z.object({
  id: z.string().uuid(),
  message: z.object({
    id: z.string().uuid(),
    role: z.enum(["user"]),
    parts: z.array(partSchema),
  }),
  selectedChatModel: z.enum(availableModelIds), // Dynamic validation
  selectedVisibilityType: z.enum(["public", "private"]),
});
```

## Model-Aware System Prompts

### Capability-Based Prompts

```typescript
// Reference: lib/ai/prompts.ts - Updated for model capabilities
export const systemPrompt = ({
  selectedModel,
  requestHints,
}: {
  selectedModel: ChatModel;
  requestHints: RequestHints;
}) => {
  const requestPrompt = getRequestPromptFromHints(requestHints);

  if (selectedModel.supportsArtifacts) {
    return `${regularPrompt}\n\n${requestPrompt}\n\n${artifactsPrompt}`;
  } else {
    return `${regularPrompt}\n\n${requestPrompt}`;
  }
};
```

## Adding New Providers

### Step-by-Step Provider Addition

1. **Add to models definition**:

```typescript
// lib/ai/models.ts
{
  id: 'openai:gpt-4o',
  name: 'GPT-4o',
  description: 'OpenAI\'s latest model',
  provider: 'openai',
  supportsReasoning: false,
  supportsArtifacts: true,
}
```

2. **Update provider mapping**:

```typescript
// lib/ai/providers.ts - Add provider case
if (model.provider === "openai") {
  models[model.id] = openai(baseModelId);
}
```

3. **Update entitlements** (if needed):

```typescript
// lib/ai/entitlements.ts - Filter by provider or model capabilities
getAvailableModels: () => {
  return chatModels.filter(
    (model) => user.tier === "premium" || model.provider === "xai"
  );
};
```

## Streaming & Data Flow

### Data Stream Pattern

```typescript
// Reference: components/data-stream-provider.tsx
export function DataStreamProvider({ children }: { children: ReactNode }) {
  const [dataStream, setDataStream] = useState<Array<DataStreamPart>>([]);

  return (
    <DataStreamContext.Provider value={{ dataStream, setDataStream }}>
      {children}
    </DataStreamContext.Provider>
  );
}
```

### Stream Data Types

```typescript
// Common data stream types
type DataStreamPart =
  | { type: "data-kind"; data: ArtifactKind; transient: true }
  | { type: "data-id"; data: string; transient: true }
  | { type: "data-title"; data: string; transient: true }
  | { type: "data-clear"; data: null; transient: true }
  | { type: "data-finish"; data: null; transient: true };
```

## Testing Multi-Provider System

### Model Configuration Testing

```typescript
// Test dynamic model mapping
describe("Provider System", () => {
  it("should map models correctly based on capabilities", () => {
    const models = createLanguageModels();

    expect(models["xai:grok-3-mini"]).toBeDefined();
    expect(models["xai:grok-3-mini-reasoning"]).toHaveProperty("middleware");
  });

  it("should filter models by user entitlements", () => {
    const guestModels = getAvailableModelsForUser("guest");
    const regularModels = getAvailableModelsForUser("regular");

    expect(guestModels.length).toBeLessThan(regularModels.length);
  });
});
```

### API Integration Testing

```typescript
// Test model validation in API routes
it("should reject invalid model selection", async () => {
  const response = await POST(
    new Request("/api/chat", {
      method: "POST",
      body: JSON.stringify({
        selectedChatModel: "invalid:model",
        message: {
          /* message data */
        },
      }),
    })
  );

  expect(response.status).toBe(403);
});
```

## Performance Considerations

### Model Selection Optimization

- **Client-side filtering** of available models based on user type
- **Caching** of model configurations
- **Lazy loading** of provider-specific modules
- **Request validation** before AI API calls

### Cost Management

- **Model-based rate limiting** (cheaper models = higher limits)
- **User tier restrictions** on premium models
- **Token usage tracking** per model and user
- **Fallback models** for reliability
