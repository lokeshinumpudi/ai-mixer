---
description: Multi-provider AI system architecture patterns for scalable model management, dynamic entitlements, and capability-based features
---

# Multi-Provider AI System Architecture

## Overview

The application implements a flexible multi-provider AI system that supports different AI providers (xAI, OpenAI, Anthropic, etc.) with dynamic model configuration, capability-based features, and user entitlements. This architecture replaces hardcoded model references with a scalable, maintainable system.

## Core Architecture Principles

### 1. Provider-Agnostic Model Interface

Models are defined with a consistent interface regardless of the underlying provider:

```typescript
// Reference: lib/ai/models.ts
export interface ChatModel {
  id: string; // Format: "provider:model-name"
  name: string; // Display name for users
  description: string; // User-friendly description
  provider: string; // Provider identifier (xai, openai, etc.)
  supportsReasoning: boolean; // Shows step-by-step reasoning
  supportsArtifacts: boolean; // Can use artifact creation tools
}
```

### 2. Dynamic Model Registration

Models are registered dynamically, making it easy to add new providers and models:

```typescript
// Reference: lib/ai/models.ts
export const chatModels: Array<ChatModel> = [
  {
    id: "xai:grok-3-mini",
    name: "Grok 3 Mini",
    description: "Fast and efficient model for general chat",
    provider: "xai",
    supportsReasoning: false,
    supportsArtifacts: true,
  },
  {
    id: "xai:grok-3-mini-reasoning",
    name: "Grok 3 Mini (Reasoning)",
    description: "Shows step-by-step reasoning for complex problems",
    provider: "xai",
    supportsReasoning: true,
    supportsArtifacts: false,
  },
  // Additional models from other providers...
];

export const DEFAULT_CHAT_MODEL: string = "xai:grok-3-mini";
```

### 3. Capability-Based Feature Control

Features are enabled/disabled based on model capabilities rather than hardcoded model checks:

```typescript
// Reference: app/(chat)/api/chat/route.ts
const result = await streamText({
  model: myProvider.languageModel(selectedChatModel),
  system: systemPrompt({ selectedModel, requestHints }),
  experimental_activeTools: selectedModel.supportsArtifacts
    ? ["getWeather", "createDocument", "updateDocument", "requestSuggestions"]
    : ["getWeather"],
  tools: {
    getWeather,
    createDocument: createDocument({ session, dataStream }),
    updateDocument: updateDocument({ session, dataStream }),
    requestSuggestions: requestSuggestions({ session, dataStream }),
  },
});

return result.toUIMessageStream({
  sendReasoning: selectedModel.supportsReasoning,
});
```

## Provider System Implementation

### 1. Dynamic Provider Mapping

The provider system dynamically maps model IDs to their implementations:

```typescript
// Reference: lib/ai/providers.ts
const createLanguageModels = () => {
  const models: Record<string, any> = {};

  // Add all chat models dynamically
  for (const model of chatModels) {
    const baseModelId = model.id.split(":")[1]; // Extract model ID after provider prefix

    if (model.provider === "xai") {
      if (model.supportsReasoning) {
        models[model.id] = wrapLanguageModel({
          model: xai(baseModelId),
          middleware: extractReasoningMiddleware({ tagName: "think" }),
        });
      } else {
        models[model.id] = xai(baseModelId);
      }
    }

    // Add other providers
    if (model.provider === "openai") {
      if (model.supportsReasoning) {
        models[model.id] = wrapLanguageModel({
          model: openai(baseModelId),
          middleware: extractReasoningMiddleware({ tagName: "thinking" }),
        });
      } else {
        models[model.id] = openai(baseModelId);
      }
    }

    // Future providers: Anthropic, Cohere, etc.
  }

  // Add special models for system functions
  models["title-model"] = xai("grok-3-mini");
  models["artifact-model"] = xai("grok-3-mini");

  return models;
};

export const myProvider = customProvider({
  languageModels: createLanguageModels(),
  imageModels: {
    "small-model": xai.imageModel("grok-2-image"),
  },
});
```

### 2. Test Environment Support

The system supports test environments with mock models:

```typescript
// Reference: lib/ai/providers.ts
const createTestLanguageModels = () => ({
  // Map new model IDs to test models for backward compatibility
  "xai:grok-3-mini": chatModel,
  "xai:grok-3-mini-reasoning": reasoningModel,
  "xai:grok-2-1212": chatModel,
  "xai:grok-2-reasoning": reasoningModel,
  "openai:gpt-4o": chatModel,
  "title-model": titleModel,
  "artifact-model": artifactModel,
});

export const myProvider = isTestEnvironment
  ? customProvider({
      languageModels: createTestLanguageModels(),
    })
  : customProvider({
      languageModels: createLanguageModels(),
      imageModels: {
        "small-model": xai.imageModel("grok-2-image"),
      },
    });
```

## Dynamic Entitlements System

### 1. Flexible User Entitlements

Entitlements are dynamic functions that can filter models based on any criteria:

```typescript
// Reference: lib/ai/entitlements.ts
interface Entitlements {
  maxMessagesPerDay: number;
  getAvailableModels: () => Array<ChatModel>;
}

export const entitlementsByUserType: Record<UserType, Entitlements> = {
  guest: {
    maxMessagesPerDay: 20,
    getAvailableModels: () => {
      // Guest users get access to basic models only
      return chatModels.filter(
        (model) => model.id.includes("grok-3-mini") // Only mini models for guests
      );
    },
  },
  regular: {
    maxMessagesPerDay: 100,
    getAvailableModels: () => {
      // Regular users get access to all models
      return chatModels;
    },
  },
  premium: {
    maxMessagesPerDay: 1000,
    getAvailableModels: () => {
      // Premium users get access to all models including expensive ones
      return chatModels;
    },
  },
};
```

### 2. Helper Functions for Backward Compatibility

```typescript
// Reference: lib/ai/entitlements.ts
export const getAvailableModelsForUser = (
  userType: UserType
): Array<ChatModel> => {
  return entitlementsByUserType[userType].getAvailableModels();
};

export const getAvailableModelIdsForUser = (
  userType: UserType
): Array<ChatModel["id"]> => {
  return getAvailableModelsForUser(userType).map((model) => model.id);
};

// Advanced filtering helpers
export const getModelsByCapability = (
  userType: UserType,
  capability: keyof Pick<ChatModel, "supportsReasoning" | "supportsArtifacts">
): Array<ChatModel> => {
  return getAvailableModelsForUser(userType).filter(
    (model) => model[capability]
  );
};

export const getModelsByProvider = (
  userType: UserType,
  provider: string
): Array<ChatModel> => {
  return getAvailableModelsForUser(userType).filter(
    (model) => model.provider === provider
  );
};
```

## API Route Integration

### 1. Model Validation and Selection

The API validates user access to selected models and configures features accordingly:

```typescript
// Reference: app/(chat)/api/chat/route.ts
export async function POST(request: Request) {
  const session = await auth();
  const { selectedChatModel } = await request.json();

  // Validate that the user has access to the selected model
  const availableModels = getAvailableModelsForUser(session.user.type);
  const selectedModel = availableModels.find(
    (model) => model.id === selectedChatModel
  );

  if (!selectedModel) {
    return new ChatSDKError("forbidden:chat").toResponse();
  }

  // Rate limiting check
  const messageCount = await getMessageCountByUserId({
    id: session.user.id,
    differenceInHours: 24,
  });

  if (
    messageCount > entitlementsByUserType[session.user.type].maxMessagesPerDay
  ) {
    return new ChatSDKError("rate_limit:chat").toResponse();
  }

  // Configure system based on model capabilities
  const result = await streamText({
    model: myProvider.languageModel(selectedChatModel),
    system: systemPrompt({ selectedModel, requestHints }),
    experimental_activeTools: selectedModel.supportsArtifacts
      ? ["getWeather", "createDocument", "updateDocument", "requestSuggestions"]
      : ["getWeather"],
    tools: {
      /* tools configuration */
    },
  });

  return result.toUIMessageStream({
    sendReasoning: selectedModel.supportsReasoning,
  });
}
```

### 2. Dynamic Schema Validation

Request schemas are generated dynamically from available models:

```typescript
// Reference: app/(chat)/api/chat/schema.ts
import { chatModels } from "@/lib/ai/models";

// Create dynamic enum from available models
const availableModelIds = chatModels.map((model) => model.id) as [
  string,
  ...string[]
];

export const postRequestBodySchema = z.object({
  id: z.string().uuid(),
  message: z.object({
    id: z.string().uuid(),
    role: z.enum(["user"]),
    parts: z.array(partSchema),
  }),
  selectedChatModel: z.enum(availableModelIds), // Dynamic validation
  selectedVisibilityType: z.enum(["public", "private"]),
});

export type PostRequestBody = z.infer<typeof postRequestBodySchema>;
```

## UI Component Integration

### 1. Model Selector Component

The model selector dynamically shows available models based on user entitlements:

```typescript
// Reference: components/model-selector.tsx
export function ModelSelector({
  session,
  selectedModelId,
  className,
}: ModelSelectorProps) {
  const [open, setOpen] = useState(false);
  const [optimisticModelId, setOptimisticModelId] =
    useOptimistic(selectedModelId);

  const userType = session.user.type;
  const availableChatModels = getAvailableModelsForUser(userType);

  const selectedChatModel = useMemo(
    () =>
      availableChatModels.find(
        (chatModel) => chatModel.id === optimisticModelId
      ),
    [optimisticModelId, availableChatModels]
  );

  return (
    <DropdownMenu open={open} onOpenChange={setOpen}>
      <DropdownMenuTrigger asChild>
        <Button variant="outline">
          {selectedChatModel?.name}
          <ChevronDownIcon />
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent>
        {availableChatModels.map((chatModel) => (
          <DropdownMenuItem
            key={chatModel.id}
            onSelect={() => {
              setOptimisticModelId(chatModel.id);
              saveChatModelAsCookie(chatModel.id);
            }}
          >
            <div className="flex flex-col">
              <div>{chatModel.name}</div>
              <div className="text-xs text-muted-foreground">
                {chatModel.description}
              </div>
              {chatModel.supportsReasoning && (
                <div className="text-xs text-blue-600">Supports Reasoning</div>
              )}
              {chatModel.supportsArtifacts && (
                <div className="text-xs text-green-600">Supports Artifacts</div>
              )}
            </div>
          </DropdownMenuItem>
        ))}
      </DropdownMenuContent>
    </DropdownMenu>
  );
}
```

### 2. Capability-Based UI Elements

UI elements adapt based on model capabilities:

```typescript
// Show reasoning indicator only for reasoning models
{
  selectedModel.supportsReasoning && (
    <div className="text-sm text-blue-600 flex items-center gap-1">
      <ThinkingIcon size={16} />
      Reasoning enabled
    </div>
  );
}

// Show artifact tools only for artifact-capable models
{
  selectedModel.supportsArtifacts && (
    <ToolBar
      tools={["createDocument", "updateDocument", "requestSuggestions"]}
      onToolSelect={handleToolSelect}
    />
  );
}
```

## Adding New Providers

### Step-by-Step Provider Addition

1. **Install provider SDK**:

```bash
npm install @ai-sdk/anthropic
```

2. **Add models to configuration**:

```typescript
// lib/ai/models.ts
{
  id: 'anthropic:claude-3-haiku',
  name: 'Claude 3 Haiku',
  description: 'Fast and cost-effective model from Anthropic',
  provider: 'anthropic',
  supportsReasoning: false,
  supportsArtifacts: true,
},
{
  id: 'anthropic:claude-3-opus',
  name: 'Claude 3 Opus',
  description: 'Most capable model from Anthropic with advanced reasoning',
  provider: 'anthropic',
  supportsReasoning: true,
  supportsArtifacts: true,
},
```

3. **Update provider mapping**:

```typescript
// lib/ai/providers.ts
import { anthropic } from "@ai-sdk/anthropic";

// In createLanguageModels function
if (model.provider === "anthropic") {
  if (model.supportsReasoning) {
    models[model.id] = wrapLanguageModel({
      model: anthropic(baseModelId),
      middleware: extractReasoningMiddleware({ tagName: "thinking" }),
    });
  } else {
    models[model.id] = anthropic(baseModelId);
  }
}
```

4. **Update entitlements** (if needed):

```typescript
// lib/ai/entitlements.ts
premium: {
  maxMessagesPerDay: 1000,
  getAvailableModels: () => {
    // Premium users get access to all providers including expensive Anthropic models
    return chatModels;
  },
},
regular: {
  maxMessagesPerDay: 100,
  getAvailableModels: () => {
    // Regular users get basic models from all providers
    return chatModels.filter(model =>
      !model.id.includes('opus') && // Exclude expensive models
      !model.id.includes('grok-2') // Exclude premium xAI models
    );
  },
},
```

5. **Add environment variables**:

```env
ANTHROPIC_API_KEY=your_api_key_here
```

6. **Update tests**:

```typescript
// lib/ai/providers.ts - test models
const createTestLanguageModels = () => ({
  "xai:grok-3-mini": chatModel,
  "anthropic:claude-3-haiku": chatModel,
  "anthropic:claude-3-opus": reasoningModel,
  // ... other test models
});
```

## Advanced Patterns

### 1. Model-Specific Configuration

Different models may require different configurations:

```typescript
// Enhanced model interface with provider-specific config
export interface ChatModel {
  id: string;
  name: string;
  description: string;
  provider: string;
  supportsReasoning: boolean;
  supportsArtifacts: boolean;
  maxTokens?: number;
  temperature?: number;
  contextWindow?: number;
  costPerMillion?: { input: number; output: number };
}

// Provider-specific model creation
const createModelWithConfig = (model: ChatModel) => {
  const baseModel = providers[model.provider](model.id.split(":")[1]);

  return {
    ...baseModel,
    maxTokens: model.maxTokens || 4096,
    temperature: model.temperature || 0.7,
  };
};
```

### 2. Cost-Aware Model Selection

Implement cost-aware features for model selection:

```typescript
// Cost-based model filtering
export const getCostEfficientModels = (
  userType: UserType
): Array<ChatModel> => {
  const availableModels = getAvailableModelsForUser(userType);

  return availableModels
    .filter((model) => model.costPerMillion)
    .sort((a, b) => {
      const aCost = a.costPerMillion!.input + a.costPerMillion!.output;
      const bCost = b.costPerMillion!.input + b.costPerMillion!.output;
      return aCost - bCost;
    });
};

// Usage in UI
const costEfficientModels = getCostEfficientModels(session.user.type);
```

### 3. Fallback Model Strategy

Implement fallback strategies for reliability:

```typescript
// Model fallback configuration
export const getModelWithFallback = async (
  primaryModelId: string,
  userType: UserType
): Promise<string> => {
  const availableModels = getAvailableModelsForUser(userType);
  const primaryModel = availableModels.find((m) => m.id === primaryModelId);

  if (!primaryModel) {
    // Fallback to default model for user type
    const fallbackModels = availableModels.filter(
      (m) => m.provider === "xai" && m.supportsArtifacts
    );
    return fallbackModels[0]?.id || DEFAULT_CHAT_MODEL;
  }

  return primaryModelId;
};
```

## Testing Multi-Provider System

### 1. Model Configuration Testing

```typescript
describe("Multi-Provider System", () => {
  it("should map all models correctly", () => {
    const models = createLanguageModels();

    // Test xAI models
    expect(models["xai:grok-3-mini"]).toBeDefined();
    expect(models["xai:grok-3-mini-reasoning"]).toHaveProperty("middleware");

    // Test future providers
    expect(models["anthropic:claude-3-haiku"]).toBeDefined();
  });

  it("should respect user entitlements", () => {
    const guestModels = getAvailableModelsForUser("guest");
    const regularModels = getAvailableModelsForUser("regular");
    const premiumModels = getAvailableModelsForUser("premium");

    expect(guestModels.length).toBeLessThan(regularModels.length);
    expect(regularModels.length).toBeLessThanOrEqual(premiumModels.length);
  });

  it("should filter by capabilities", () => {
    const reasoningModels = getModelsByCapability(
      "regular",
      "supportsReasoning"
    );
    const artifactModels = getModelsByCapability(
      "regular",
      "supportsArtifacts"
    );

    expect(reasoningModels.every((m) => m.supportsReasoning)).toBe(true);
    expect(artifactModels.every((m) => m.supportsArtifacts)).toBe(true);
  });
});
```

### 2. API Integration Testing

```typescript
describe("API Model Validation", () => {
  it("should reject invalid model selection", async () => {
    const response = await POST(
      new Request("/api/chat", {
        method: "POST",
        body: JSON.stringify({
          selectedChatModel: "invalid:model",
          message: {
            /* message data */
          },
        }),
      })
    );

    expect(response.status).toBe(403);
  });

  it("should enforce user entitlements", async () => {
    // Mock guest user trying to use premium model
    const response = await POST(
      new Request("/api/chat", {
        method: "POST",
        headers: { authorization: "Bearer guest_token" },
        body: JSON.stringify({
          selectedChatModel: "anthropic:claude-3-opus",
          message: {
            /* message data */
          },
        }),
      })
    );

    expect(response.status).toBe(403);
  });
});
```

### 3. UI Component Testing

```typescript
describe("ModelSelector", () => {
  it("should show only entitled models", () => {
    render(
      <ModelSelector
        session={{ user: { type: "guest" } }}
        selectedModelId="xai:grok-3-mini"
      />
    );

    // Should not show premium models for guest users
    expect(screen.queryByText("Claude 3 Opus")).not.toBeInTheDocument();
    expect(screen.getByText("Grok 3 Mini")).toBeInTheDocument();
  });

  it("should indicate model capabilities", () => {
    render(
      <ModelSelector
        session={mockSession}
        selectedModelId="xai:grok-3-mini-reasoning"
      />
    );

    expect(screen.getByText("Supports Reasoning")).toBeInTheDocument();
  });
});
```

## Migration Strategies

### 1. Gradual Migration from Hardcoded Models

```typescript
// Backward compatibility during migration
const LEGACY_MODEL_MAPPING = {
  "chat-model": "xai:grok-3-mini",
  "chat-model-reasoning": "xai:grok-3-mini-reasoning",
} as const;

export const normalizeModelId = (modelId: string): string => {
  // Handle legacy model IDs
  if (modelId in LEGACY_MODEL_MAPPING) {
    return LEGACY_MODEL_MAPPING[modelId as keyof typeof LEGACY_MODEL_MAPPING];
  }

  // Return new format as-is
  return modelId;
};
```

### 2. Feature Flag for New System

```typescript
const USE_MULTI_PROVIDER = process.env.NEXT_PUBLIC_MULTI_PROVIDER === "true";

export const getModel = (modelId: string) => {
  if (USE_MULTI_PROVIDER) {
    return myProvider.languageModel(normalizeModelId(modelId));
  } else {
    // Legacy single provider logic
    return legacyProvider.languageModel(modelId);
  }
};
```

This multi-provider architecture provides a scalable foundation for supporting multiple AI providers while maintaining clean separation of concerns and enabling flexible feature rollouts based on model capabilities and user entitlements.
